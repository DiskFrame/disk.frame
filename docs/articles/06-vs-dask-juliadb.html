<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Benchmarks 1: disk.frame beats Dask! disk.frame beats JuliaDB! Anyone else wanna challenge? • disk.frame</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Benchmarks 1: disk.frame beats Dask! disk.frame beats JuliaDB! Anyone else wanna challenge?">
<meta property="og:description" content="disk.frame">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">disk.frame</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.3.6</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/01-intro.html">Preface - The birth of `disk.frame`</a>
    </li>
    <li>
      <a href="../articles/02-intro-disk-frame.html">Quick Start: Basic Operations with nycflights13</a>
    </li>
    <li>
      <a href="../articles/03-concepts.html">Key `{disk.frame}` concepts</a>
    </li>
    <li>
      <a href="../articles/04-ingesting-data.html">Ingesting Data</a>
    </li>
    <li>
      <a href="../articles/05-data-table-syntax.html">Using data.table syntax with disk.frame</a>
    </li>
    <li>
      <a href="../articles/06-vs-dask-juliadb.html">Benchmarks 1: disk.frame beats Dask! disk.frame beats JuliaDB! Anyone else wanna challenge?</a>
    </li>
    <li>
      <a href="../articles/07-glm.html">Generalized Linear Models (GLM) including logistic regression with disk.frame</a>
    </li>
    <li>
      <a href="../articles/08-more-epic.html">{disk.frame} can be more 'epic'</a>
    </li>
    <li>
      <a href="../articles/09-convenience-features.html">Convenience features</a>
    </li>
    <li>
      <a href="../articles/10-group-by.html">Group-by</a>
    </li>
    <li>
      <a href="../articles/11-custom-group-by.html">Custom One-Stage Group-by functions</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/xiaodaigh/disk.frame/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Benchmarks 1: disk.frame beats Dask! disk.frame beats JuliaDB! Anyone else wanna challenge?</h1>
                        <h4 class="author">ZJ</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/xiaodaigh/disk.frame/blob/master/vignettes/06-vs-dask-juliadb.Rmd"><code>vignettes/06-vs-dask-juliadb.Rmd</code></a></small>
      <div class="hidden name"><code>06-vs-dask-juliadb.Rmd</code></div>

    </div>

    
    
<div id="intro---benchmark-1" class="section level1">
<h1 class="hasAnchor">
<a href="#intro---benchmark-1" class="anchor"></a>Intro - Benchmark 1</h1>
<p>This is the first in a series to benchmark the performance of disk.frame vs other medium-data tools. For Python, we will benchmark Dask, and for Julia, we will benchmark JuliaDB.jl. In the process, I will do a warts-and-all account of the tools I have tested.</p>
<p>The title was ‘inspired’ by <a href="https://matloff.wordpress.com/2014/05/21/r-beats-python-r-beats-julia-anyone-else-wanna-challenge-r/">this post titled “R beats Python! R beats Julia! Anyone else wanna challenge R?”</a>.</p>
</div>
<div id="tldr" class="section level1">
<h1 class="hasAnchor">
<a href="#tldr" class="anchor"></a>TL;DR</h1>
<p>For this simple benchmark, disk.frame is faster. But Dask has a more convenient syntax. JuliaDB.jl is not ready for prime time.</p>
<div id="timings" class="section level4">
<h4 class="hasAnchor">
<a href="#timings" class="anchor"></a>Timings</h4>
<p>Please note I have not tried to record the precise times over many runs, but I aim illustrate the magnitude of speed of the different packages</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">ggplot2</span>)

<span class="no">df</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(
  <span class="kw">tool</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"disk.frame"</span>, <span class="st">"Dask"</span>, <span class="st">"JuliaDB.jl"</span>),
  <span class="kw">timing</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">17.9</span>, <span class="fl">50</span>, <span class="fl">76</span>)
)

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">df</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">tool</span>, <span class="kw">weight</span> <span class="kw">=</span> <span class="no">timing</span>), <span class="kw">stat</span> <span class="kw">=</span> <span class="st">"count"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"seconds"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span>(<span class="st">"Convert to desired format timing"</span>)</pre></body></html></div>
<p><img src="06-vs-dask-juliadb_files/figure-html/unnamed-chunk-2-1.png" width="700"></p>
<p>Next up is timings for the simple aggregation</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="no">df</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(
  <span class="kw">tool</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"disk.frame"</span>, <span class="st">"Dask"</span>, <span class="st">"JuliaDB.jl"</span>),
  <span class="kw">timing</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>, <span class="fl">1.2</span>, <span class="fl">6</span>)
)

<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">ggplot2</span>)
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">df</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">tool</span>, <span class="kw">weight</span> <span class="kw">=</span> <span class="no">timing</span>), <span class="kw">stat</span> <span class="kw">=</span> <span class="st">"count"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"seconds"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span>(<span class="st">"Count(*) group-by timings"</span>)</pre></body></html></div>
<p><img src="06-vs-dask-juliadb_files/figure-html/unnamed-chunk-3-1.png" width="700"></p>
</div>
<div id="data" class="section level2">
<h2 class="hasAnchor">
<a href="#data" class="anchor"></a>Data</h2>
<p>The data can be obtained from <a href="https://docs.rapids.ai/datasets/mortgage-data">Rapids.ai’s Fannie Mae Data distribution page</a>. I have downloaded the <a href="http://rapidsai-data.s3-website.us-east-2.amazonaws.com/notebook-mortgage-data/mortgage_2000-2016.tgz">17 Years data</a> which contains dat on 37 million loans with over 1.89 billions rows in Performance datasets.</p>
<p>To download and the data, here are some examples</p>
<p>For <em>Linux</em> users</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">wget</span> http://rapidsai-data.s3-website.us-east-2.amazonaws.com/notebook-mortgage-data/mortgage_2000-2016.tgz</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="fu">tar</span> xzvg mortgage_2000-2016.tgz</span></code></pre></div>
<p>For <em>Mac</em> users</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="ex">curl</span> http://rapidsai-data.s3-website.us-east-2.amazonaws.com/notebook-mortgage-data/mortgage_2000-2016.tgz -o mortgage_2000-2016.tgz</span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="fu">tar</span> xzvg mortgage_2000-2016.tgz</span></code></pre></div>
<p>For <em>Windows</em> users, just download the file and extract the tgz file.</p>
</div>
<div id="benchmark-exercise-converting-csv-to-desired-format-and-simple-aggregation" class="section level2">
<h2 class="hasAnchor">
<a href="#benchmark-exercise-converting-csv-to-desired-format-and-simple-aggregation" class="anchor"></a>Benchmark exercise: converting CSV to desired format and simple aggregation</h2>
<p>We find the largest possible single file to give each of the tool a test run.</p>
<div id="disk-frame" class="section level4">
<h4 class="hasAnchor">
<a href="#disk-frame" class="anchor"></a>disk.frame</h4>
<p>First up is disk.frame</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/message.html">suppressPackageStartupMessages</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">disk.frame</span>))
<span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span>(<span class="fu"><a href="../reference/setup_disk.frame.html">setup_disk.frame</a></span>()) <span class="co"># ~4s</span>
<span class="co">#&gt; The number of workers available for disk.frame is 6</span>
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;    0.04    0.05    4.64</span></pre></body></html></div>
<p>We note that there is some time needed for disk.frame to start up all the workers. Next we try to convert the largest CSV file to disk.frame format. The file to be converted is about 2.2GB in size</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="no">time_to_convert_disk.frame</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span>(<span class="no">df1</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/csv_to_disk.frame.html">csv_to_disk.frame</a></span>(<span class="st">"c:/data/Performance_2004Q3.txt"</span>, <span class="kw">header</span> <span class="kw">=</span> <span class="fl">FALSE</span>))[<span class="fl">3</span>]

<span class="no">time_to_convert_disk.frame</span>
<span class="co">#&gt; elapsed </span>
<span class="co">#&gt;   20.27</span></pre></body></html></div>
<p>Now that we have converted it, we want to a count by the first column. To achieve this we use a “two-stage” aggregation strategy. Note that use <code>keep="V1"</code> to bring only the column <code>V1</code> into RAM. This avoids the reading of other unnecessary columns and should speed-up the analysis significantly</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="no">time_to_agg_disk.frame</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span>(<span class="no">summ</span> <span class="kw">&lt;-</span> <span class="no">df1</span>[,<span class="no">.N</span>, <span class="no">V1</span>, <span class="kw">keep</span> <span class="kw">=</span> <span class="st">"V1"</span>][, <span class="fu">.</span>(<span class="kw">N</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">N</span>)), <span class="no">V1</span>])

<span class="no">time_to_agg_disk.frame</span>
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;    0.14    0.03    7.39</span></pre></body></html></div>
<p>We can inspect the result as well.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="no">summ</span>
<span class="co">#&gt;                   V1   N</span>
<span class="co">#&gt;      1: 100001458647 111</span>
<span class="co">#&gt;      2: 100004788186  95</span>
<span class="co">#&gt;      3: 100008528816 133</span>
<span class="co">#&gt;      4: 100014656651 115</span>
<span class="co">#&gt;      5: 100021529837  75</span>
<span class="co">#&gt;     ---                 </span>
<span class="co">#&gt; 389486: 999981910757  17</span>
<span class="co">#&gt; 389487: 999982397951 104</span>
<span class="co">#&gt; 389488: 999986952752  97</span>
<span class="co">#&gt; 389489: 999990008973 156</span>
<span class="co">#&gt; 389490: 999994125744  15</span></pre></body></html></div>
<p>Another way to perform the analysis is to use <code>dplyr</code> syntax to perform group-by in <em>one-stage</em> which is:</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span>(<span class="no">df1</span> <span class="kw">%&gt;%</span>
  <span class="fu"><a href="../reference/srckeep.html">srckeep</a></span>(<span class="st">"V1"</span>) <span class="kw">%&gt;%</span>
  <span class="fu">group_by</span>(<span class="no">V1</span>) <span class="kw">%&gt;%</span>
  <span class="fu">summarise</span>(<span class="kw">N</span> <span class="kw">=</span> <span class="fu">n</span>()) <span class="kw">%&gt;%</span>
  <span class="no">collect</span>)
<span class="co">#&gt;    user  system elapsed </span>
<span class="co">#&gt;    1.82    0.25    6.61</span></pre></body></html></div>
<p>However, the <code>dplyr</code> syntax tends to be slightly slower than using data.table syntax. This may be improved as much of the overhead is due to inefficient use of NSE.</p>
</div>
<div id="dask" class="section level4">
<h4 class="hasAnchor">
<a href="#dask" class="anchor"></a>Dask</h4>
<p>To test Dask</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="im">import</span> dask.dataframe <span class="im">as</span> dd</span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb10-3"><a href="#cb10-3"></a></span>
<span id="cb10-4"><a href="#cb10-4"></a>a <span class="op">=</span> dd.read_csv(<span class="st">"c:/data/Performance_2004Q3.txt"</span>, sep<span class="op">=</span><span class="st">"|"</span>,</span>
<span id="cb10-5"><a href="#cb10-5"></a>                dtype<span class="op">=</span>{<span class="dv">7</span>: <span class="st">'double'</span>, <span class="dv">14</span>: <span class="st">'str'</span>, <span class="dv">15</span>: <span class="st">'str'</span>, <span class="dv">16</span>:<span class="st">'str'</span>}, header <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb10-6"><a href="#cb10-6"></a>a.columns <span class="op">=</span> [<span class="st">"var"</span> <span class="op">+</span> <span class="bu">str</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">31</span>)]</span>
<span id="cb10-7"><a href="#cb10-7"></a>a.head()</span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a>startTime <span class="op">=</span> datetime.now()</span>
<span id="cb10-10"><a href="#cb10-10"></a>a.to_parquet(<span class="st">"c:/data/p03.parquet"</span>)</span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="bu">print</span>(datetime.now() <span class="op">-</span> startTime)  <span class="co"># 50 seconds</span></span></code></pre></div>
<p>and we can see that converting to Parquet takes more time than <code>csv_to_disk.frame</code>. Now to test Dask’s ability to aggregate a simple use-case, we can also load only column into RAM to speed up the analysis.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>startTime <span class="op">=</span> datetime.now()</span>
<span id="cb11-2"><a href="#cb11-2"></a>a <span class="op">=</span> dd.read_parquet(<span class="st">"c:/data/p03.parquet"</span>, columns<span class="op">=</span><span class="st">"var0"</span>)</span>
<span id="cb11-3"><a href="#cb11-3"></a>aa <span class="op">=</span> a.value_counts().compute()</span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="bu">print</span>(datetime.now() <span class="op">-</span> startTime)  <span class="co"># 1.2</span></span></code></pre></div>
<p>The aggregation time is also longer, although in practice 1.2s. vs around 0.5s isn’t that big of a difference. We shall see how the differential changes when dealing with larger datasets in a future session.</p>
<div id="dask-is-good" class="section level5">
<h5 class="hasAnchor">
<a href="#dask-is-good" class="anchor"></a>Dask is good</h5>
<p>A good feature of Dask is that you need not convert the data to parquet before doing the aggregation. This is a very convenient feature that is not available in disk.frame yet. For example:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>startTime <span class="op">=</span> datetime.now()</span>
<span id="cb12-2"><a href="#cb12-2"></a>a <span class="op">=</span> dd.read_csv(<span class="st">"c:/data/perf/Performance_2004Q3.txt"</span>, sep<span class="op">=</span><span class="st">"|"</span>,</span>
<span id="cb12-3"><a href="#cb12-3"></a>                dtype<span class="op">=</span>{<span class="dv">7</span>: <span class="st">'double'</span>, <span class="dv">14</span>: <span class="st">'str'</span>, <span class="dv">15</span>: <span class="st">'str'</span>, <span class="dv">16</span>:<span class="st">'str'</span>}, header <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb12-4"><a href="#cb12-4"></a>a.columns <span class="op">=</span> [<span class="st">"var"</span> <span class="op">+</span> <span class="bu">str</span>(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">31</span>)]</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a>startTime <span class="op">=</span> datetime.now()</span>
<span id="cb12-7"><a href="#cb12-7"></a>a.var0.value_counts().compute()</span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="bu">print</span>(datetime.now() <span class="op">-</span> startTime)  <span class="co"># 50 seconds</span></span></code></pre></div>
<p>However this strategy is not particularly fast. In practice, you are almost always better off spending some time to convert your data to a efficient format before performing analysis. This may have a time cost, but the effort will pay off very quickly.</p>
</div>
</div>
<div id="juliadb" class="section level4">
<h4 class="hasAnchor">
<a href="#juliadb" class="anchor"></a>JuliaDB</h4>
<p>I really like Julia but it’s a shame that JuliaDB is no where near as mature as either disk.frame nor Dask for inputting data. I have not been able to load the CSV using JuliaDB’s native methods and have resorted to using CSV.jl to read the data and convert it to JuliaDB.jl. Also, it’s difficult to figure out how to run JuliaDB from disk, and the memory usage is enormous compared to the disk.frame’s and Dask’s.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode julia"><code class="sourceCode julia"><span id="cb13-1"><a href="#cb13-1"></a>using JuliaDB, CSV, OnlineStats</span>
<span id="cb13-2"><a href="#cb13-2"></a>path = <span class="st">"c:/data/perf"</span></span>
<span id="cb13-3"><a href="#cb13-3"></a></span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="co"># read data using CSV.jl and convert to JuliaDB</span></span>
<span id="cb13-5"><a href="#cb13-5"></a>@time df = CSV.File(joinpath(path, <span class="st">"Performance_2004Q3.txt"</span>), delim = <span class="ch">'|'</span>, header = false) |&gt; JuliaDB.table <span class="co"># 48</span></span></code></pre></div>
<p>Once the data has been loaded, I can aggregate as follows</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode julia"><code class="sourceCode julia"><span id="cb14-1"><a href="#cb14-1"></a>using LambdaFn</span>
<span id="cb14-2"><a href="#cb14-2"></a>@time groupby(@λ(size(_,<span class="fl">1</span>)), a, :Column1) <span class="co"># 6</span></span></code></pre></div>
<p>Unfortunately, it’s much slower than both disk.frame and Dask.</p>
<p>As a side note, I can use OnlineStats.jl to do aggregation (relatively) efficiently. I think OnlineStats is one of the bright spots for JuliaDB, as it has powerful online-algorithms that allows you to combine statistics by computing those statistics in chunks and combining the results from each chunk. It’s a shame that JuliaDB is not mature enough to make it shine more brightly. For an example of what it can do, see the example to compute the mean of <code>Column6</code> grouped by <code>Column1</code></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode julia"><code class="sourceCode julia"><span id="cb15-1"><a href="#cb15-1"></a>@time groupreduce(Mean(), a, :Column1, select = :Column6)</span></code></pre></div>
<p>You may have noticed that we have not converted JuliaDB.jl to disk. Here we will try that</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode julia"><code class="sourceCode julia"><span id="cb16-1"><a href="#cb16-1"></a>@time JuliaDB.save(a, <span class="st">"c:/data/.jldb"</span>) <span class="co"># 26s</span></span></code></pre></div>
<p>Together with the time taken to read the data in (48s), we can say that the time to read and convert to the JuliaDB format is 48s + 28s = 76s. The issue with this conversion is that we are still not able to load only the column we need for the analysis. Random access to columns are possible with disk.frame and Dask.</p>
<p>Also, it’s astounding that the output file is 17GB in size and the original CSV was only 2.5GB! Loading the data takes about 9s, but uses up a lot of RAM. I think it will take time for JuliaDB to mature.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode julia"><code class="sourceCode julia"><span id="cb17-1"><a href="#cb17-1"></a>@time a = JuliaDB.load(<span class="st">"c:/data/.jldb"</span>) <span class="co"># 0s</span></span></code></pre></div>
</div>
</div>
<div id="conclusion" class="section level2">
<h2 class="hasAnchor">
<a href="#conclusion" class="anchor"></a>Conclusion</h2>
<p>It is somewhat surprising that disk.frame is the speed king in this benchmark study, but I can’t take any of the credit as the speediness of disk.frame is due to the authors of fst, future (and parallel), and data.table. It’s also no surprise that Julia’s medium-data tool lags behind Python’s and R’s, because it’s a pattern noticed elsewhere in the data ecosystem. Julia’s niche and strength at this point is in computational problems that require lots of computation that do not necessarily involved large amounts of input data (the Celeste project appears to be an exception but I think the computational demand there dominate the data demand).</p>
<p>Although disk.frame is the fastest, it’s syntax is not as convenient as Dask’s. Using Dask is almost the same as using pandas. In contrast, when using disk.frame, the user needs to be aware that operations happen in chunks, and hence a “two-stage” group-by is required. However, this will be addressed in a future planned package disk.frame.db which is will allow the user to “forget” the underlying architecture is made of chunks, and just focus on higher-level data operations.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Dai ZJ.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
